[I 2025-05-20 23:26:44,139] A new study created in memory with name: no-name-400021a0-9147-48a8-a470-2caeb8455924
/home/sethih1/masque_new/ters_gen/hyperopt.py:23: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.
  batch_size = trial.suggest_int('batch_size', *config.training.batch_sizes)
/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/optuna/distributions.py:699: UserWarning: The distribution is specified by [32, 64] and step=128, but the range is not divisible by `step`. It will be replaced by [32, 32].
  warnings.warn(
/home/sethih1/masque_new/ters_gen/hyperopt.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lr = trial.suggest_loguniform('lr', config.training.learning_rates[0], config.training.learning_rates[-1])
[W 2025-05-20 23:26:44,193] Trial 0 failed with parameters: {'batch_size': 32, 'lr': 0.00031480706713875404, 'loss_fn': 'dice_loss'} because of the following error: TypeError("AttentionUNet.__init__() got an unexpected keyword argument 'type'").
Traceback (most recent call last):
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/home/sethih1/masque_new/ters_gen/hyperopt.py", line 97, in <lambda>
    study.optimize(lambda t: objective(t, config, device), n_trials = config.training.n_trials, n_jobs=config.training.n_jobs)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sethih1/masque_new/ters_gen/hyperopt.py", line 61, in objective
    model = AttentionUNet(**config.model).to(device)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: AttentionUNet.__init__() got an unexpected keyword argument 'type'
[W 2025-05-20 23:26:44,194] Trial 0 failed with value None.
[Trial 0] Trying batch_size=32, lr=0.00031480706713875404, loss_fn=dice_loss
Traceback (most recent call last):
  File "/home/sethih1/masque_new/ters_gen/hyperopt.py", line 106, in <module>
    main()
  File "/home/sethih1/masque_new/ters_gen/hyperopt.py", line 97, in main
    study.optimize(lambda t: objective(t, config, device), n_trials = config.training.n_trials, n_jobs=config.training.n_jobs)
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/optuna/study/study.py", line 475, in optimize
    _optimize(
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/optuna/study/_optimize.py", line 63, in _optimize
    _optimize_sequential(
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/optuna/study/_optimize.py", line 160, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/optuna/study/_optimize.py", line 248, in _run_trial
    raise func_err
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/home/sethih1/masque_new/ters_gen/hyperopt.py", line 97, in <lambda>
    study.optimize(lambda t: objective(t, config, device), n_trials = config.training.n_trials, n_jobs=config.training.n_jobs)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sethih1/masque_new/ters_gen/hyperopt.py", line 61, in objective
    model = AttentionUNet(**config.model).to(device)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: AttentionUNet.__init__() got an unexpected keyword argument 'type'
