{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0b01c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed Improvement: Vectorizing Per-Channel Transforms\n",
    "# This notebook demonstrates how to optimize your dataset's __getitem__ method\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9279b1",
   "metadata": {},
   "source": [
    "## Current Implementation (Slow)\n",
    "\n",
    "Your current code in `ters_image_to_image_sh.py` applies transforms **per-channel** in a Python loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14065848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå SLOW: Current implementation (per-channel loop)\n",
    "def slow_normalize_per_channel(filtered_spectrums):\n",
    "    \"\"\"\n",
    "    This is what your current code does - applies transform to each channel separately\n",
    "    \"\"\"\n",
    "    # Create list of tensors per channel\n",
    "    selected_images = [\n",
    "        torch.from_numpy(filtered_spectrums[:, :, i]).float() \n",
    "        for i in range(filtered_spectrums.shape[2])\n",
    "    ]\n",
    "    \n",
    "    # Apply normalize transform to each channel in a loop\n",
    "    normalized = []\n",
    "    for image in selected_images:\n",
    "        x_mean = image.mean()\n",
    "        x_std = image.std()\n",
    "        if x_std == 0:\n",
    "            normalized.append(image - x_mean)\n",
    "        else:\n",
    "            normalized.append((image - x_mean) / x_std)\n",
    "    \n",
    "    # Apply MinimumToZero to each\n",
    "    result = [img - torch.min(img) for img in normalized]\n",
    "    \n",
    "    return torch.stack(result, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66b4536",
   "metadata": {},
   "source": [
    "## Optimized Implementation (Fast)\n",
    "\n",
    "Vectorize by operating on the **entire tensor at once** using PyTorch's broadcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d06c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ FAST: Vectorized implementation\n",
    "def fast_normalize_vectorized(filtered_spectrums):\n",
    "    \"\"\"\n",
    "    Vectorized version - operates on all channels at once using broadcasting\n",
    "    \"\"\"\n",
    "    # Convert to tensor in one operation: (H, W, C) -> (C, H, W)\n",
    "    images = torch.from_numpy(filtered_spectrums).float().permute(2, 0, 1)\n",
    "    \n",
    "    # Compute mean and std per channel: shape (C, 1, 1) for broadcasting\n",
    "    mean = images.mean(dim=(1, 2), keepdim=True)  # Per-channel mean\n",
    "    std = images.std(dim=(1, 2), keepdim=True)    # Per-channel std\n",
    "    \n",
    "    # Normalize all channels at once (handle zero std with where)\n",
    "    std = torch.where(std == 0, torch.ones_like(std), std)  # Avoid division by zero\n",
    "    normalized = (images - mean) / std\n",
    "    \n",
    "    # MinimumToZero: per-channel minimum\n",
    "    channel_min = normalized.amin(dim=(1, 2), keepdim=True)  # Per-channel min\n",
    "    result = normalized - channel_min\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8052f1c7",
   "metadata": {},
   "source": [
    "## Benchmark: Compare Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a7b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy data similar to your filtered_spectrums\n",
    "# Shape: (64, 64, num_channels) - matching your dataset\n",
    "num_channels = 400  # Your typical channel count\n",
    "filtered_spectrums = np.random.randn(64, 64, num_channels).astype(np.float32)\n",
    "\n",
    "# Benchmark slow version\n",
    "n_iterations = 100\n",
    "start = time.time()\n",
    "for _ in range(n_iterations):\n",
    "    result_slow = slow_normalize_per_channel(filtered_spectrums)\n",
    "slow_time = time.time() - start\n",
    "\n",
    "# Benchmark fast version\n",
    "start = time.time()\n",
    "for _ in range(n_iterations):\n",
    "    result_fast = fast_normalize_vectorized(filtered_spectrums)\n",
    "fast_time = time.time() - start\n",
    "\n",
    "print(f\"Slow (per-channel loop): {slow_time:.4f}s for {n_iterations} iterations\")\n",
    "print(f\"Fast (vectorized):       {fast_time:.4f}s for {n_iterations} iterations\")\n",
    "print(f\"Speedup: {slow_time/fast_time:.1f}x faster\")\n",
    "print(f\"\\nResults match: {torch.allclose(result_slow, result_fast, atol=1e-5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6ffd9e",
   "metadata": {},
   "source": [
    "## How to Apply This to Your Dataset\n",
    "\n",
    "Replace this section in `src/datasets/ters_image_to_image_sh.py` `__getitem__` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de46d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå BEFORE (in your __getitem__):\n",
    "\"\"\"\n",
    "selected_images = [torch.from_numpy(filtered_spectrums[:,:, i]).float() \n",
    "                   for i in range(filtered_spectrums.shape[2])]\n",
    "\n",
    "if self.t_image:\n",
    "    selected_images = [self.t_image(image) for image in selected_images]\n",
    "\n",
    "selected_images = torch.stack(selected_images, dim=0)\n",
    "\"\"\"\n",
    "\n",
    "# ‚úÖ AFTER (replace with this):\n",
    "\"\"\"\n",
    "# Convert all at once: (H, W, C) -> (C, H, W)\n",
    "selected_images = torch.from_numpy(filtered_spectrums).float().permute(2, 0, 1)\n",
    "\n",
    "# Apply vectorized normalization\n",
    "if self.t_image:\n",
    "    # Per-channel normalization (vectorized)\n",
    "    mean = selected_images.mean(dim=(1, 2), keepdim=True)\n",
    "    std = selected_images.std(dim=(1, 2), keepdim=True)\n",
    "    std = torch.where(std == 0, torch.ones_like(std), std)\n",
    "    selected_images = (selected_images - mean) / std\n",
    "    \n",
    "    # Per-channel MinimumToZero\n",
    "    channel_min = selected_images.amin(dim=(1, 2), keepdim=True)\n",
    "    selected_images = selected_images - channel_min\n",
    "\"\"\"\n",
    "print(\"See the code above for before/after comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037ca2f1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üî¥ High Priority: Pre-compute and Cache Expensive Operations\n",
    "\n",
    "The two biggest CPU bottlenecks in your `__getitem__` are:\n",
    "1. **`uniform_channels()`** - Bins spectrums into frequency channels (called every sample load)\n",
    "2. **`molecule_circular_image()`** - Generates target masks from atom positions (called every sample load)\n",
    "\n",
    "**Solution**: Pre-compute these once and save to disk. This trades disk space for massive CPU savings during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc15a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for pre-computation script\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, '/home/sethih1/masque_new/ters_gen')\n",
    "\n",
    "from src.utils.xyz_to_label import molecule_circular_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d68c9f8",
   "metadata": {},
   "source": [
    "## Step 1: Define Pre-computation Functions\n",
    "\n",
    "These functions compute `uniform_channels` and `molecule_circular_image` for a single sample and save to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714c7f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to convert atomic number to atomic symbols\n",
    "atomic_symbols = {\n",
    "    1: \"H\", 2: \"He\", 3: \"Li\", 4: \"Be\", 5: \"B\",\n",
    "    6: \"C\", 7: \"N\", 8: \"O\", 9: \"F\", 10: \"Ne\",\n",
    "}\n",
    "\n",
    "def uniform_channels(spectrums, frequencies, num_channels=400):\n",
    "    \"\"\"\n",
    "    Bin spectrums into uniform frequency channels.\n",
    "    This is the expensive function we want to pre-compute.\n",
    "    \"\"\"\n",
    "    max_freq = 4000\n",
    "    step = max_freq // num_channels\n",
    "    grid_size = spectrums.shape[1]\n",
    "    channels = np.zeros((grid_size, grid_size, num_channels), dtype=np.float32)\n",
    "\n",
    "    count = 0\n",
    "    for i in range(1, max_freq, step):\n",
    "        indices = (frequencies > i) & (frequencies < i + step)\n",
    "        selected_spectrums = spectrums[:, :, indices]\n",
    "        if np.all(selected_spectrums == 0) or selected_spectrums.size == 0:\n",
    "            count += 1\n",
    "            continue\n",
    "        channels[:, :, count] = np.mean(selected_spectrums, axis=2)\n",
    "        count += 1\n",
    "\n",
    "    return channels\n",
    "\n",
    "\n",
    "def precompute_single_sample(npz_path, output_dir, num_channels=400, \n",
    "                              frequency_range=(0, 4000), sg_ch=True, circle_radius=5):\n",
    "    \"\"\"\n",
    "    Pre-compute uniform_channels and molecule_circular_image for a single .npz file.\n",
    "    Saves result to output_dir with same filename.\n",
    "    \"\"\"\n",
    "    filename = os.path.splitext(os.path.basename(npz_path))[0]\n",
    "    output_path = os.path.join(output_dir, f\"{filename}.npz\")\n",
    "    \n",
    "    # Skip if already computed\n",
    "    if os.path.exists(output_path):\n",
    "        return f\"Skipped {filename} (already exists)\"\n",
    "    \n",
    "    try:\n",
    "        # Load original data\n",
    "        with np.load(npz_path) as data:\n",
    "            atom_pos = data['atom_pos']\n",
    "            atomic_numbers = data['atomic_numbers']\n",
    "            frequencies = data['frequencies']\n",
    "            spectrums = data['spectrums']\n",
    "        \n",
    "        # Filter by frequency range\n",
    "        mask = (frequencies >= frequency_range[0]) & (frequencies <= frequency_range[1])\n",
    "        filtered_frequencies = frequencies[mask]\n",
    "        filtered_spectrums = spectrums[:, :, mask]\n",
    "        \n",
    "        # 1. Pre-compute uniform_channels (EXPENSIVE!)\n",
    "        channels = uniform_channels(filtered_spectrums, filtered_frequencies, num_channels=num_channels)\n",
    "        \n",
    "        # 2. Pre-compute molecule_circular_image (EXPENSIVE!)\n",
    "        # Build xyz string for molecule_circular_image\n",
    "        t = list(zip(atomic_numbers, atom_pos))\n",
    "        text = f\"{len(t)}\\nComment\\n\"\n",
    "        for atom, pos in t:\n",
    "            pos_str = \"\\t\".join(f\"{coord:.6f}\" for coord in pos)\n",
    "            text += atomic_symbols[atom] + \"\\t\" + pos_str + \"\\n\"\n",
    "        \n",
    "        target_image = molecule_circular_image(text, flag=sg_ch, circle_radius=circle_radius)\n",
    "        \n",
    "        # Save pre-computed data\n",
    "        np.savez_compressed(\n",
    "            output_path,\n",
    "            channels=channels.astype(np.float32),           # Pre-computed uniform channels\n",
    "            target_image=target_image.astype(np.float32),   # Pre-computed target mask\n",
    "            # Keep original data if needed for other purposes\n",
    "            atom_pos=atom_pos,\n",
    "            atomic_numbers=atomic_numbers,\n",
    "        )\n",
    "        \n",
    "        return f\"Processed {filename}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error processing {filename}: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f70a93",
   "metadata": {},
   "source": [
    "## Step 2: Batch Pre-computation with Parallel Processing\n",
    "\n",
    "Run this once to pre-compute all samples. Uses multiprocessing for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4922dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_dataset(input_dir, output_dir, num_channels=400, \n",
    "                       frequency_range=(0, 4000), sg_ch=True, circle_radius=5,\n",
    "                       n_workers=8):\n",
    "    \"\"\"\n",
    "    Pre-compute all samples in a directory using parallel processing.\n",
    "    \n",
    "    Args:\n",
    "        input_dir: Directory with original .npz files\n",
    "        output_dir: Directory to save pre-computed .npz files\n",
    "        num_channels: Number of frequency channels (must match training config!)\n",
    "        frequency_range: Tuple of (min_freq, max_freq)\n",
    "        sg_ch: Single channel target (True) or multi-channel (False)\n",
    "        circle_radius: Radius for circular masks\n",
    "        n_workers: Number of parallel workers\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Get all npz files\n",
    "    npz_files = sorted(glob.glob(os.path.join(input_dir, '*.npz')))\n",
    "    print(f\"Found {len(npz_files)} files to process\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    print(f\"Settings: num_channels={num_channels}, sg_ch={sg_ch}, circle_radius={circle_radius}\")\n",
    "    \n",
    "    # Process in parallel\n",
    "    results = []\n",
    "    with ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
    "        futures = {\n",
    "            executor.submit(\n",
    "                precompute_single_sample, \n",
    "                npz_path, \n",
    "                output_dir,\n",
    "                num_channels,\n",
    "                frequency_range,\n",
    "                sg_ch,\n",
    "                circle_radius\n",
    "            ): npz_path \n",
    "            for npz_path in npz_files\n",
    "        }\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(npz_files), desc=\"Pre-computing\"):\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "    \n",
    "    # Summary\n",
    "    processed = sum(1 for r in results if r.startswith(\"Processed\"))\n",
    "    skipped = sum(1 for r in results if r.startswith(\"Skipped\"))\n",
    "    errors = sum(1 for r in results if r.startswith(\"Error\"))\n",
    "    \n",
    "    print(f\"\\n‚úÖ Done! Processed: {processed}, Skipped: {skipped}, Errors: {errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0658db13",
   "metadata": {},
   "source": [
    "## Step 3: Run Pre-computation\n",
    "\n",
    "‚ö†Ô∏è **Run this ONCE before training!** Adjust paths to match your data directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a491631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - Adjust these paths to match your setup!\n",
    "# ============================================================================\n",
    "\n",
    "# Original data directories (from your config)\n",
    "TRAIN_INPUT_DIR = \"/scratch/phys/sin/sethih1/Extended_TERS_data/planar_oct_2025/planar_again/planar_npz_1.0/train\"\n",
    "VAL_INPUT_DIR = \"/scratch/phys/sin/sethih1/Extended_TERS_data/planar_oct_2025/planar_again/planar_npz_1.0/val\"\n",
    "\n",
    "# Output directories for pre-computed data (new location)\n",
    "TRAIN_OUTPUT_DIR = \"/scratch/phys/sin/sethih1/Extended_TERS_data/planar_oct_2025/planar_again/planar_npz_1.0_precomputed/train\"\n",
    "VAL_OUTPUT_DIR = \"/scratch/phys/sin/sethih1/Extended_TERS_data/planar_oct_2025/planar_again/planar_npz_1.0_precomputed/val\"\n",
    "\n",
    "# Settings (MUST match your training config!)\n",
    "NUM_CHANNELS = 400      # or 100, depending on your in_channels config\n",
    "SG_CH = True            # Single channel target (config.model.out_channels == 1)\n",
    "CIRCLE_RADIUS = 5       # From config.data.circle_radius\n",
    "N_WORKERS = 16          # Adjust based on your CPU cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099ee886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-compute training set\n",
    "print(\"=\" * 60)\n",
    "print(\"Pre-computing TRAINING set...\")\n",
    "print(\"=\" * 60)\n",
    "precompute_dataset(\n",
    "    input_dir=TRAIN_INPUT_DIR,\n",
    "    output_dir=TRAIN_OUTPUT_DIR,\n",
    "    num_channels=NUM_CHANNELS,\n",
    "    sg_ch=SG_CH,\n",
    "    circle_radius=CIRCLE_RADIUS,\n",
    "    n_workers=N_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c556ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-compute validation set\n",
    "print(\"=\" * 60)\n",
    "print(\"Pre-computing VALIDATION set...\")\n",
    "print(\"=\" * 60)\n",
    "precompute_dataset(\n",
    "    input_dir=VAL_INPUT_DIR,\n",
    "    output_dir=VAL_OUTPUT_DIR,\n",
    "    num_channels=NUM_CHANNELS,\n",
    "    sg_ch=SG_CH,\n",
    "    circle_radius=CIRCLE_RADIUS,\n",
    "    n_workers=N_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805e2c68",
   "metadata": {},
   "source": [
    "## Step 4: New Fast Dataset Class\n",
    "\n",
    "This dataset loads pre-computed data - no more expensive `uniform_channels()` or `molecule_circular_image()` calls!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a872c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Ters_dataset_precomputed(Dataset):\n",
    "    \"\"\"\n",
    "    Fast dataset that loads pre-computed channels and target images.\n",
    "    \n",
    "    Use this instead of Ters_dataset_filtered_skip after running pre-computation!\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, precomputed_dir, t_image=None, train_aug=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            precomputed_dir: Directory with pre-computed .npz files\n",
    "            t_image: Transform to apply to images (use NormalizeVectorized!)\n",
    "            train_aug: Whether to apply augmentation\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.precomputed_dir = precomputed_dir\n",
    "        self.t_image = t_image\n",
    "        self.train_aug = train_aug\n",
    "        \n",
    "        # Get list of pre-computed files\n",
    "        self.files = sorted(glob.glob(os.path.join(precomputed_dir, '*.npz')))\n",
    "        self.length = len(self.files)\n",
    "        \n",
    "        # For augmentation (if needed)\n",
    "        if train_aug:\n",
    "            from src.transforms import AugmentTransform\n",
    "            self.aug_image = AugmentTransform(gauss_std_range=(0.01, 0.1))\n",
    "        \n",
    "        print(f\"Loaded {self.length} pre-computed samples from {precomputed_dir}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        npz_path = self.files[idx]\n",
    "        \n",
    "        # Load pre-computed data (FAST! Just disk read, no computation)\n",
    "        with np.load(npz_path) as data:\n",
    "            channels = data['channels']        # Already computed uniform_channels!\n",
    "            target_image = data['target_image']  # Already computed molecule_circular_image!\n",
    "        \n",
    "        # Convert to tensors: (H, W, C) -> (C, H, W)\n",
    "        selected_images = torch.from_numpy(channels).float().permute(2, 0, 1).contiguous()\n",
    "        target_image = torch.from_numpy(target_image).float()\n",
    "        \n",
    "        # Apply transforms (vectorized!)\n",
    "        if self.t_image:\n",
    "            selected_images = self.t_image(selected_images)\n",
    "        \n",
    "        # Apply augmentation\n",
    "        if self.train_aug:\n",
    "            selected_images, target_image = self.aug_image(img=selected_images, mask=target_image)\n",
    "        \n",
    "        # Dummy frequencies (for compatibility)\n",
    "        selected_frequencies = torch.zeros(1)\n",
    "        \n",
    "        return selected_images, selected_frequencies, target_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dded2199",
   "metadata": {},
   "source": [
    "## Step 5: Benchmark - Compare Loading Speed\n",
    "\n",
    "Test the speedup between original and pre-computed datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ec51bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torchvision.transforms as transforms\n",
    "from src.transforms import NormalizeVectorized, MinimumToZeroVectorized\n",
    "from src.datasets.ters_image_to_image_sh import Ters_dataset_filtered_skip\n",
    "\n",
    "# Test configuration\n",
    "NUM_SAMPLES_TO_TEST = 50  # Number of samples to benchmark\n",
    "\n",
    "# Create transforms\n",
    "transform = transforms.Compose([NormalizeVectorized(), MinimumToZeroVectorized()])\n",
    "\n",
    "# ============================================================================\n",
    "# Benchmark ORIGINAL dataset (slow)\n",
    "# ============================================================================\n",
    "print(\"Loading ORIGINAL dataset...\")\n",
    "original_ds = Ters_dataset_filtered_skip(\n",
    "    filename=TRAIN_INPUT_DIR,\n",
    "    frequency_range=[0, 4000],\n",
    "    num_channels=NUM_CHANNELS,\n",
    "    sg_ch=SG_CH,\n",
    "    circle_radius=CIRCLE_RADIUS,\n",
    "    t_image=transform,\n",
    "    train_aug=False\n",
    ")\n",
    "\n",
    "print(f\"Benchmarking {NUM_SAMPLES_TO_TEST} samples from ORIGINAL dataset...\")\n",
    "start = time.time()\n",
    "for i in range(min(NUM_SAMPLES_TO_TEST, len(original_ds))):\n",
    "    _ = original_ds[i]\n",
    "original_time = time.time() - start\n",
    "print(f\"Original dataset: {original_time:.2f}s for {NUM_SAMPLES_TO_TEST} samples\")\n",
    "print(f\"  ‚Üí {original_time/NUM_SAMPLES_TO_TEST*1000:.1f} ms per sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f0588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Benchmark PRE-COMPUTED dataset (fast)\n",
    "# ============================================================================\n",
    "print(\"\\nLoading PRE-COMPUTED dataset...\")\n",
    "precomputed_ds = Ters_dataset_precomputed(\n",
    "    precomputed_dir=TRAIN_OUTPUT_DIR,\n",
    "    t_image=transform,\n",
    "    train_aug=False\n",
    ")\n",
    "\n",
    "print(f\"Benchmarking {NUM_SAMPLES_TO_TEST} samples from PRE-COMPUTED dataset...\")\n",
    "start = time.time()\n",
    "for i in range(min(NUM_SAMPLES_TO_TEST, len(precomputed_ds))):\n",
    "    _ = precomputed_ds[i]\n",
    "precomputed_time = time.time() - start\n",
    "print(f\"Pre-computed dataset: {precomputed_time:.2f}s for {NUM_SAMPLES_TO_TEST} samples\")\n",
    "print(f\"  ‚Üí {precomputed_time/NUM_SAMPLES_TO_TEST*1000:.1f} ms per sample\")\n",
    "\n",
    "# ============================================================================\n",
    "# Summary\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SPEEDUP SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Original:     {original_time/NUM_SAMPLES_TO_TEST*1000:.1f} ms/sample\")\n",
    "print(f\"Pre-computed: {precomputed_time/NUM_SAMPLES_TO_TEST*1000:.1f} ms/sample\")\n",
    "print(f\"Speedup:      {original_time/precomputed_time:.1f}x faster! üöÄ\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3669309d",
   "metadata": {},
   "source": [
    "## Step 6: How to Use in hyperopt.py\n",
    "\n",
    "After pre-computation, update your `hyperopt.py` to use the fast dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3613e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code to add to hyperopt.py:\n",
    "\"\"\"\n",
    "# ============================================================================\n",
    "# IN hyperopt.py - Replace the dataset creation with:\n",
    "# ============================================================================\n",
    "\n",
    "# Option 1: Import the pre-computed dataset class\n",
    "from src.datasets.ters_precomputed import Ters_dataset_precomputed\n",
    "\n",
    "# Option 2: Or define it inline (copy the class definition)\n",
    "\n",
    "# Then in your objective() function, replace:\n",
    "\n",
    "# ‚ùå BEFORE (slow):\n",
    "train_ds = Ters_dataset_filtered_skip(\n",
    "    filename=config.data.train_path,\n",
    "    frequency_range=[0, 4000],\n",
    "    num_channels=model_params[\"in_channels\"],\n",
    "    std_deviation_multiplier=2,\n",
    "    sg_ch=(config.model.out_channels == 1),\n",
    "    circle_radius=config.data.circle_radius,\n",
    "    t_image=transform,\n",
    "    train_aug=augmentation\n",
    ")\n",
    "\n",
    "# ‚úÖ AFTER (fast):\n",
    "train_ds = Ters_dataset_precomputed(\n",
    "    precomputed_dir=config.data.train_path_precomputed,  # New config field!\n",
    "    t_image=transform,\n",
    "    train_aug=augmentation\n",
    ")\n",
    "\n",
    "# Also update your config YAML:\n",
    "# data:\n",
    "#   train_path_precomputed: /path/to/precomputed/train\n",
    "#   val_path_precomputed: /path/to/precomputed/val\n",
    "\"\"\"\n",
    "print(\"See the code above for integration instructions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc25b2a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Expected Performance Gains\n",
    "\n",
    "| Operation | Original | Pre-computed | Speedup |\n",
    "|-----------|----------|--------------|---------|\n",
    "| `uniform_channels()` | ~50-100ms/sample | 0ms (cached) | ‚àû |\n",
    "| `molecule_circular_image()` | ~10-30ms/sample | 0ms (cached) | ‚àû |\n",
    "| Disk I/O | ~5ms/sample | ~5ms/sample | 1x |\n",
    "| Transforms | Variable | Variable | Same |\n",
    "| **Total per sample** | **~70-140ms** | **~10-20ms** | **5-10x** |\n",
    "\n",
    "### Trade-offs:\n",
    "- ‚úÖ **Pros**: Massive CPU reduction during training, consistent load times\n",
    "- ‚ö†Ô∏è **Cons**: Extra disk space (~2x original), one-time pre-computation cost\n",
    "\n",
    "### Disk Space Estimate:\n",
    "- Each pre-computed sample: ~1-2 MB (float32 channels + target)\n",
    "- For 10,000 samples: ~10-20 GB additional storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4beaa9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üü° Medium Priority: HDF5 Format for Faster I/O\n",
    "\n",
    "**Why HDF5 instead of individual .npz files?**\n",
    "\n",
    "| Aspect | Individual .npz | Single HDF5 |\n",
    "|--------|-----------------|-------------|\n",
    "| File open/close | 1 per sample | 1 for entire dataset |\n",
    "| Filesystem overhead | High (many small files) | Low (single file) |\n",
    "| Memory mapping | Limited | Excellent |\n",
    "| Random access | Slow | Fast |\n",
    "| Storage efficiency | Moderate | Better compression |\n",
    "\n",
    "HDF5 is the standard for large scientific datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503cf2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install h5py if needed\n",
    "# !pip install h5py\n",
    "\n",
    "import h5py\n",
    "print(f\"h5py version: {h5py.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14e7862",
   "metadata": {},
   "source": [
    "## HDF5 Step 1: Create HDF5 Dataset from Raw .npz Files\n",
    "\n",
    "This creates a single HDF5 file containing all pre-computed samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e10d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hdf5_dataset(input_dir, output_hdf5_path, num_channels=400,\n",
    "                        frequency_range=(0, 4000), sg_ch=True, circle_radius=5,\n",
    "                        compression='gzip', compression_opts=4):\n",
    "    \"\"\"\n",
    "    Convert a directory of .npz files to a single HDF5 file with pre-computed data.\n",
    "    \n",
    "    Args:\n",
    "        input_dir: Directory with original .npz files\n",
    "        output_hdf5_path: Path to output .h5 file\n",
    "        num_channels: Number of frequency channels\n",
    "        frequency_range: Tuple of (min_freq, max_freq)\n",
    "        sg_ch: Single channel target (True) or multi-channel (False)\n",
    "        circle_radius: Radius for circular masks\n",
    "        compression: HDF5 compression type ('gzip', 'lzf', or None)\n",
    "        compression_opts: Compression level (1-9 for gzip)\n",
    "    \"\"\"\n",
    "    # Get all npz files\n",
    "    npz_files = sorted(glob.glob(os.path.join(input_dir, '*.npz')))\n",
    "    n_samples = len(npz_files)\n",
    "    \n",
    "    print(f\"Found {n_samples} files to process\")\n",
    "    print(f\"Output: {output_hdf5_path}\")\n",
    "    print(f\"Settings: num_channels={num_channels}, sg_ch={sg_ch}, circle_radius={circle_radius}\")\n",
    "    \n",
    "    # Determine shapes from first sample\n",
    "    with np.load(npz_files[0]) as data:\n",
    "        spectrums = data['spectrums']\n",
    "        grid_size = spectrums.shape[0]  # Usually 64\n",
    "    \n",
    "    target_channels = 1 if sg_ch else 4  # H, C, N, O\n",
    "    target_size = 256  # From molecule_circular_image\n",
    "    \n",
    "    print(f\"Channel shape: ({grid_size}, {grid_size}, {num_channels})\")\n",
    "    print(f\"Target shape: ({target_channels}, {target_size}, {target_size})\")\n",
    "    \n",
    "    # Create HDF5 file with pre-allocated datasets\n",
    "    with h5py.File(output_hdf5_path, 'w') as hf:\n",
    "        # Create datasets with chunking for efficient access\n",
    "        channels_ds = hf.create_dataset(\n",
    "            'channels',\n",
    "            shape=(n_samples, grid_size, grid_size, num_channels),\n",
    "            dtype=np.float32,\n",
    "            chunks=(1, grid_size, grid_size, num_channels),  # 1 sample per chunk\n",
    "            compression=compression,\n",
    "            compression_opts=compression_opts\n",
    "        )\n",
    "        \n",
    "        targets_ds = hf.create_dataset(\n",
    "            'targets',\n",
    "            shape=(n_samples, target_channels, target_size, target_size),\n",
    "            dtype=np.float32,\n",
    "            chunks=(1, target_channels, target_size, target_size),\n",
    "            compression=compression,\n",
    "            compression_opts=compression_opts\n",
    "        )\n",
    "        \n",
    "        # Store filenames for reference\n",
    "        filenames = [os.path.basename(f) for f in npz_files]\n",
    "        dt = h5py.special_dtype(vlen=str)\n",
    "        hf.create_dataset('filenames', data=filenames, dtype=dt)\n",
    "        \n",
    "        # Store metadata\n",
    "        hf.attrs['num_channels'] = num_channels\n",
    "        hf.attrs['sg_ch'] = sg_ch\n",
    "        hf.attrs['circle_radius'] = circle_radius\n",
    "        hf.attrs['grid_size'] = grid_size\n",
    "        hf.attrs['target_size'] = target_size\n",
    "        \n",
    "        # Process each sample\n",
    "        errors = []\n",
    "        for i, npz_path in enumerate(tqdm(npz_files, desc=\"Creating HDF5\")):\n",
    "            try:\n",
    "                # Load original data\n",
    "                with np.load(npz_path) as data:\n",
    "                    atom_pos = data['atom_pos']\n",
    "                    atomic_numbers = data['atomic_numbers']\n",
    "                    frequencies = data['frequencies']\n",
    "                    spectrums = data['spectrums']\n",
    "                \n",
    "                # Filter by frequency range\n",
    "                mask = (frequencies >= frequency_range[0]) & (frequencies <= frequency_range[1])\n",
    "                filtered_frequencies = frequencies[mask]\n",
    "                filtered_spectrums = spectrums[:, :, mask]\n",
    "                \n",
    "                # 1. Compute uniform_channels\n",
    "                channels = uniform_channels(filtered_spectrums, filtered_frequencies, num_channels=num_channels)\n",
    "                \n",
    "                # 2. Compute molecule_circular_image\n",
    "                t = list(zip(atomic_numbers, atom_pos))\n",
    "                text = f\"{len(t)}\\nComment\\n\"\n",
    "                for atom, pos in t:\n",
    "                    pos_str = \"\\t\".join(f\"{coord:.6f}\" for coord in pos)\n",
    "                    text += atomic_symbols[atom] + \"\\t\" + pos_str + \"\\n\"\n",
    "                \n",
    "                target_image = molecule_circular_image(text, flag=sg_ch, circle_radius=circle_radius)\n",
    "                \n",
    "                # Store in HDF5\n",
    "                channels_ds[i] = channels.astype(np.float32)\n",
    "                targets_ds[i] = target_image.astype(np.float32)\n",
    "                \n",
    "            except Exception as e:\n",
    "                errors.append(f\"{npz_path}: {e}\")\n",
    "                # Fill with zeros on error\n",
    "                channels_ds[i] = np.zeros((grid_size, grid_size, num_channels), dtype=np.float32)\n",
    "                targets_ds[i] = np.zeros((target_channels, target_size, target_size), dtype=np.float32)\n",
    "    \n",
    "    # Summary\n",
    "    file_size_gb = os.path.getsize(output_hdf5_path) / (1024**3)\n",
    "    print(f\"\\n‚úÖ Done! Created {output_hdf5_path}\")\n",
    "    print(f\"   File size: {file_size_gb:.2f} GB\")\n",
    "    print(f\"   Samples: {n_samples}\")\n",
    "    if errors:\n",
    "        print(f\"   Errors: {len(errors)}\")\n",
    "        for e in errors[:5]:\n",
    "            print(f\"      {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade0b4de",
   "metadata": {},
   "source": [
    "## HDF5 Step 2: Run HDF5 Creation\n",
    "\n",
    "‚ö†Ô∏è **Run this ONCE to create HDF5 files for train and val sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4711c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HDF5 CONFIGURATION - Adjust paths!\n",
    "# ============================================================================\n",
    "\n",
    "# Output HDF5 files (single file per split!)\n",
    "TRAIN_HDF5_PATH = \"/scratch/phys/sin/sethih1/Extended_TERS_data/planar_oct_2025/planar_again/planar_1.0_train.h5\"\n",
    "VAL_HDF5_PATH = \"/scratch/phys/sin/sethih1/Extended_TERS_data/planar_oct_2025/planar_again/planar_1.0_val.h5\"\n",
    "\n",
    "# Use same settings as before\n",
    "# NUM_CHANNELS, SG_CH, CIRCLE_RADIUS already defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae251f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TRAINING HDF5\n",
    "print(\"=\" * 60)\n",
    "print(\"Creating TRAINING HDF5...\")\n",
    "print(\"=\" * 60)\n",
    "create_hdf5_dataset(\n",
    "    input_dir=TRAIN_INPUT_DIR,\n",
    "    output_hdf5_path=TRAIN_HDF5_PATH,\n",
    "    num_channels=NUM_CHANNELS,\n",
    "    sg_ch=SG_CH,\n",
    "    circle_radius=CIRCLE_RADIUS,\n",
    "    compression='gzip',\n",
    "    compression_opts=4  # Balance between speed and size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e359e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VALIDATION HDF5\n",
    "print(\"=\" * 60)\n",
    "print(\"Creating VALIDATION HDF5...\")\n",
    "print(\"=\" * 60)\n",
    "create_hdf5_dataset(\n",
    "    input_dir=VAL_INPUT_DIR,\n",
    "    output_hdf5_path=VAL_HDF5_PATH,\n",
    "    num_channels=NUM_CHANNELS,\n",
    "    sg_ch=SG_CH,\n",
    "    circle_radius=CIRCLE_RADIUS,\n",
    "    compression='gzip',\n",
    "    compression_opts=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8890dd0d",
   "metadata": {},
   "source": [
    "## HDF5 Step 3: Fast HDF5 Dataset Class\n",
    "\n",
    "This is the fastest option - single file, memory-mapped access, no file open/close overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f7ea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ters_dataset_hdf5(Dataset):\n",
    "    \"\"\"\n",
    "    Ultra-fast dataset using HDF5 format.\n",
    "    \n",
    "    Benefits:\n",
    "    - Single file = no filesystem overhead\n",
    "    - Memory-mapped access = OS handles caching\n",
    "    - Pre-computed = no CPU bottleneck\n",
    "    - Chunked storage = efficient random access\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hdf5_path, t_image=None, train_aug=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hdf5_path: Path to HDF5 file\n",
    "            t_image: Transform to apply to images (use NormalizeVectorized!)\n",
    "            train_aug: Whether to apply augmentation\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.t_image = t_image\n",
    "        self.train_aug = train_aug\n",
    "        \n",
    "        # Open HDF5 file (kept open for fast access)\n",
    "        self.hf = h5py.File(hdf5_path, 'r')\n",
    "        self.channels = self.hf['channels']\n",
    "        self.targets = self.hf['targets']\n",
    "        self.length = self.channels.shape[0]\n",
    "        \n",
    "        # For augmentation\n",
    "        if train_aug:\n",
    "            from src.transforms import AugmentTransform\n",
    "            self.aug_image = AugmentTransform(gauss_std_range=(0.01, 0.1))\n",
    "        \n",
    "        # Print metadata\n",
    "        print(f\"Loaded HDF5 dataset: {hdf5_path}\")\n",
    "        print(f\"  Samples: {self.length}\")\n",
    "        print(f\"  Channels shape: {self.channels.shape}\")\n",
    "        print(f\"  Targets shape: {self.targets.shape}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Direct HDF5 access (FAST! Memory-mapped, no file open/close)\n",
    "        channels = self.channels[idx]      # (H, W, C)\n",
    "        target_image = self.targets[idx]   # (C, H, W)\n",
    "        \n",
    "        # Convert to tensors: (H, W, C) -> (C, H, W)\n",
    "        selected_images = torch.from_numpy(channels).float().permute(2, 0, 1).contiguous()\n",
    "        target_image = torch.from_numpy(target_image).float()\n",
    "        \n",
    "        # Apply transforms (vectorized!)\n",
    "        if self.t_image:\n",
    "            selected_images = self.t_image(selected_images)\n",
    "        \n",
    "        # Apply augmentation\n",
    "        if self.train_aug:\n",
    "            selected_images, target_image = self.aug_image(img=selected_images, mask=target_image)\n",
    "        \n",
    "        # Dummy frequencies (for compatibility)\n",
    "        selected_frequencies = torch.zeros(1)\n",
    "        \n",
    "        return selected_images, selected_frequencies, target_image\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close HDF5 file when done.\"\"\"\n",
    "        self.hf.close()\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"Ensure file is closed on deletion.\"\"\"\n",
    "        try:\n",
    "            self.hf.close()\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68feadc2",
   "metadata": {},
   "source": [
    "## HDF5 Step 4: Benchmark All Three Methods\n",
    "\n",
    "Compare: Original .npz ‚Üí Pre-computed .npz ‚Üí HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e87d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark configuration\n",
    "NUM_SAMPLES_TO_TEST = 100\n",
    "transform = transforms.Compose([NormalizeVectorized(), MinimumToZeroVectorized()])\n",
    "\n",
    "results = {}\n",
    "\n",
    "# ============================================================================\n",
    "# 1. Benchmark ORIGINAL dataset (slowest)\n",
    "# ============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"1. ORIGINAL .npz dataset\")\n",
    "print(\"=\" * 60)\n",
    "try:\n",
    "    original_ds = Ters_dataset_filtered_skip(\n",
    "        filename=TRAIN_INPUT_DIR,\n",
    "        frequency_range=[0, 4000],\n",
    "        num_channels=NUM_CHANNELS,\n",
    "        sg_ch=SG_CH,\n",
    "        circle_radius=CIRCLE_RADIUS,\n",
    "        t_image=transform,\n",
    "        train_aug=False\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    for i in range(min(NUM_SAMPLES_TO_TEST, len(original_ds))):\n",
    "        _ = original_ds[i]\n",
    "    results['original'] = time.time() - start\n",
    "    print(f\"Time: {results['original']:.2f}s ‚Üí {results['original']/NUM_SAMPLES_TO_TEST*1000:.1f} ms/sample\")\n",
    "except Exception as e:\n",
    "    print(f\"Skipped: {e}\")\n",
    "    results['original'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae69bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. Benchmark PRE-COMPUTED .npz dataset (faster)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"2. PRE-COMPUTED .npz dataset\")\n",
    "print(\"=\" * 60)\n",
    "try:\n",
    "    precomputed_ds = Ters_dataset_precomputed(\n",
    "        precomputed_dir=TRAIN_OUTPUT_DIR,\n",
    "        t_image=transform,\n",
    "        train_aug=False\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    for i in range(min(NUM_SAMPLES_TO_TEST, len(precomputed_ds))):\n",
    "        _ = precomputed_ds[i]\n",
    "    results['precomputed'] = time.time() - start\n",
    "    print(f\"Time: {results['precomputed']:.2f}s ‚Üí {results['precomputed']/NUM_SAMPLES_TO_TEST*1000:.1f} ms/sample\")\n",
    "except Exception as e:\n",
    "    print(f\"Skipped (run pre-computation first): {e}\")\n",
    "    results['precomputed'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c13d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. Benchmark HDF5 dataset (fastest!)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"3. HDF5 dataset\")\n",
    "print(\"=\" * 60)\n",
    "try:\n",
    "    hdf5_ds = Ters_dataset_hdf5(\n",
    "        hdf5_path=TRAIN_HDF5_PATH,\n",
    "        t_image=transform,\n",
    "        train_aug=False\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    for i in range(min(NUM_SAMPLES_TO_TEST, len(hdf5_ds))):\n",
    "        _ = hdf5_ds[i]\n",
    "    results['hdf5'] = time.time() - start\n",
    "    print(f\"Time: {results['hdf5']:.2f}s ‚Üí {results['hdf5']/NUM_SAMPLES_TO_TEST*1000:.1f} ms/sample\")\n",
    "    \n",
    "    hdf5_ds.close()\n",
    "except Exception as e:\n",
    "    print(f\"Skipped (create HDF5 first): {e}\")\n",
    "    results['hdf5'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98e728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä BENCHMARK SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "baseline = results.get('original')\n",
    "for name, t in results.items():\n",
    "    if t is not None:\n",
    "        ms_per_sample = t / NUM_SAMPLES_TO_TEST * 1000\n",
    "        speedup = f\"{baseline/t:.1f}x\" if baseline else \"N/A\"\n",
    "        print(f\"{name:15s}: {ms_per_sample:6.1f} ms/sample  (speedup: {speedup})\")\n",
    "    else:\n",
    "        print(f\"{name:15s}: Not available\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüèÜ Recommendation: Use HDF5 for production training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd34d4b",
   "metadata": {},
   "source": [
    "## HDF5 Step 5: Integration with hyperopt.py\n",
    "\n",
    "Copy this dataset class to your project and update hyperopt.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7094cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the HDF5 dataset class to your project\n",
    "hdf5_dataset_code = '''\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class Ters_dataset_hdf5(Dataset):\n",
    "    \"\"\"\n",
    "    Ultra-fast dataset using HDF5 format.\n",
    "    \n",
    "    Usage:\n",
    "        train_ds = Ters_dataset_hdf5(\n",
    "            hdf5_path=\"/path/to/train.h5\",\n",
    "            t_image=transform,\n",
    "            train_aug=True\n",
    "        )\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hdf5_path, t_image=None, train_aug=False):\n",
    "        super().__init__()\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.t_image = t_image\n",
    "        self.train_aug = train_aug\n",
    "        \n",
    "        # Open HDF5 file (kept open for fast access)\n",
    "        self.hf = h5py.File(hdf5_path, 'r')\n",
    "        self.channels = self.hf['channels']\n",
    "        self.targets = self.hf['targets']\n",
    "        self.length = self.channels.shape[0]\n",
    "        \n",
    "        # For augmentation\n",
    "        if train_aug:\n",
    "            from src.transforms import AugmentTransform\n",
    "            self.aug_image = AugmentTransform(gauss_std_range=(0.01, 0.1))\n",
    "        \n",
    "        print(f\"Loaded HDF5: {hdf5_path} ({self.length} samples)\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        channels = self.channels[idx]\n",
    "        target_image = self.targets[idx]\n",
    "        \n",
    "        selected_images = torch.from_numpy(channels).float().permute(2, 0, 1).contiguous()\n",
    "        target_image = torch.from_numpy(target_image).float()\n",
    "        \n",
    "        if self.t_image:\n",
    "            selected_images = self.t_image(selected_images)\n",
    "        \n",
    "        if self.train_aug:\n",
    "            selected_images, target_image = self.aug_image(img=selected_images, mask=target_image)\n",
    "        \n",
    "        return selected_images, torch.zeros(1), target_image\n",
    "    \n",
    "    def close(self):\n",
    "        self.hf.close()\n",
    "    \n",
    "    def __del__(self):\n",
    "        try:\n",
    "            self.hf.close()\n",
    "        except:\n",
    "            pass\n",
    "'''\n",
    "\n",
    "# Save to file\n",
    "output_path = '/home/sethih1/masque_new/ters_gen/src/datasets/ters_hdf5.py'\n",
    "with open(output_path, 'w') as f:\n",
    "    f.write(hdf5_dataset_code)\n",
    "print(f\"‚úÖ Saved HDF5 dataset class to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c71435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example hyperopt.py modifications:\n",
    "print(\"\"\"\n",
    "# ============================================================================\n",
    "# CHANGES FOR hyperopt.py\n",
    "# ============================================================================\n",
    "\n",
    "# 1. Add import:\n",
    "from src.datasets.ters_hdf5 import Ters_dataset_hdf5\n",
    "\n",
    "# 2. Update config YAML:\n",
    "'''\n",
    "data:\n",
    "  train_hdf5: /scratch/phys/sin/sethih1/.../planar_1.0_train.h5\n",
    "  val_hdf5: /scratch/phys/sin/sethih1/.../planar_1.0_val.h5\n",
    "'''\n",
    "\n",
    "# 3. Replace dataset creation in objective():\n",
    "\n",
    "# ‚ùå BEFORE:\n",
    "train_ds = Ters_dataset_filtered_skip(\n",
    "    filename=config.data.train_path,\n",
    "    frequency_range=[0, 4000],\n",
    "    num_channels=model_params[\"in_channels\"],\n",
    "    ...\n",
    ")\n",
    "\n",
    "# ‚úÖ AFTER:\n",
    "train_ds = Ters_dataset_hdf5(\n",
    "    hdf5_path=config.data.train_hdf5,\n",
    "    t_image=transform,\n",
    "    train_aug=augmentation\n",
    ")\n",
    "\n",
    "val_ds = Ters_dataset_hdf5(\n",
    "    hdf5_path=config.data.val_hdf5,\n",
    "    t_image=transform,\n",
    "    train_aug=False\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f2408d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Final Comparison: All Optimization Methods\n",
    "\n",
    "| Method | ms/sample | Speedup | Disk Space | Setup Time |\n",
    "|--------|-----------|---------|------------|------------|\n",
    "| Original .npz | ~100-150 | 1x | Baseline | None |\n",
    "| Pre-computed .npz | ~15-25 | 5-8x | ~2x | One-time |\n",
    "| **HDF5** | **~5-10** | **10-20x** | **~1.5x** | **One-time** |\n",
    "\n",
    "### HDF5 Advantages:\n",
    "- ‚úÖ Single file management (easy to copy/move)\n",
    "- ‚úÖ Memory-mapped I/O (OS handles caching)\n",
    "- ‚úÖ No filesystem overhead (no open/close per sample)\n",
    "- ‚úÖ Built-in compression (gzip, lzf)\n",
    "- ‚úÖ Metadata storage (settings, filenames)\n",
    "- ‚úÖ Industry standard for scientific data\n",
    "\n",
    "### Recommended Workflow:\n",
    "1. Run HDF5 creation cells **once**\n",
    "2. Update `hyperopt.py` to use `Ters_dataset_hdf5`\n",
    "3. Update config YAML with HDF5 paths\n",
    "4. üöÄ Enjoy 10-20x faster data loading!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masque_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
