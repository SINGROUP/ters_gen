[I 2025-05-23 16:44:49,300] A new study created in memory with name: no-name-c3e203b9-a28b-4bca-8d17-1044cb94cc80
/home/sethih1/masque_new/ters_gen/hyperopt.py:23: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.
  batch_size = trial.suggest_int('batch_size', *config.training.batch_sizes)
/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/optuna/distributions.py:699: UserWarning: The distribution is specified by [32, 64] and step=128, but the range is not divisible by `step`. It will be replaced by [32, 32].
  warnings.warn(
/home/sethih1/masque_new/ters_gen/hyperopt.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lr = trial.suggest_loguniform('lr', config.training.learning_rates[0], config.training.learning_rates[-1])
[W 2025-05-23 16:44:49,306] Trial 0 failed with parameters: {'batch_size': 32, 'lr': 0.0006540340698245211, 'loss_fn': 'bce_loss'} because of the following error: TypeError("AttentionUNet.__init__() got an unexpected keyword argument 'type'").
Traceback (most recent call last):
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/home/sethih1/masque_new/ters_gen/hyperopt.py", line 100, in <lambda>
    study.optimize(lambda t: objective(t, config, device), n_trials = config.training.n_trials, n_jobs=config.training.n_jobs)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sethih1/masque_new/ters_gen/hyperopt.py", line 61, in objective
    model = AttentionUNet(**config.model).to(device)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: AttentionUNet.__init__() got an unexpected keyword argument 'type'
[W 2025-05-23 16:44:49,307] Trial 0 failed with value None.
[Trial 0] Trying batch_size=32, lr=0.0006540340698245211, loss_fn=bce_loss
Traceback (most recent call last):
  File "/home/sethih1/masque_new/ters_gen/hyperopt.py", line 109, in <module>
    main()
  File "/home/sethih1/masque_new/ters_gen/hyperopt.py", line 100, in main
    study.optimize(lambda t: objective(t, config, device), n_trials = config.training.n_trials, n_jobs=config.training.n_jobs)
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/optuna/study/study.py", line 475, in optimize
    _optimize(
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/optuna/study/_optimize.py", line 63, in _optimize
    _optimize_sequential(
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/optuna/study/_optimize.py", line 160, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/optuna/study/_optimize.py", line 248, in _run_trial
    raise func_err
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/home/sethih1/masque_new/ters_gen/hyperopt.py", line 100, in <lambda>
    study.optimize(lambda t: objective(t, config, device), n_trials = config.training.n_trials, n_jobs=config.training.n_jobs)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sethih1/masque_new/ters_gen/hyperopt.py", line 61, in objective
    model = AttentionUNet(**config.model).to(device)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: AttentionUNet.__init__() got an unexpected keyword argument 'type'
