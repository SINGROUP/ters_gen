wandb: creating run
wandb: creating run
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in /home/sethih1/masque_new/ters_gen/wandb/run-20251021_111252-qt3o1rjd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_2_bs16_lr2e-05_dice_loss
wandb: ‚≠êÔ∏è View project at https://wandb.ai/sethih10-epfl/Extended_TERS_data
wandb: üöÄ View run at https://wandb.ai/sethih10-epfl/Extended_TERS_data/runs/qt3o1rjd
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in /home/sethih1/masque_new/ters_gen/wandb/run-20251021_111252-6l2yu577
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_3_bs128_lr1e-05_dice_loss
wandb: ‚≠êÔ∏è View project at https://wandb.ai/sethih10-epfl/Extended_TERS_data
wandb: üöÄ View run at https://wandb.ai/sethih10-epfl/Extended_TERS_data/runs/6l2yu577
wandb: 500 encountered ({"errors":[{"message":"An internal error occurred. Please contact support.","path":["upsertBucket"]}],"data":{"upsertBucket":null}}), retrying request
wandb: 500 encountered ({"errors":[{"message":"An internal error occurred. Please contact support.","path":["upsertBucket"]}],"data":{"upsertBucket":null}}), retrying request
Exception in trial 3: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Exception in trial 2: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/sethih1/masque_new/ters_gen/hyperopt.py", line 80, in objective
    model = get_model(config.model.type, model_params).to(device)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sethih1/masque_new/ters_gen/hyperopt.py", line 80, in objective
    model = get_model(config.model.type, model_params).to(device)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1340, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1340, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 900, in _apply
    module._apply(fn)
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 900, in _apply
    module._apply(fn)
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 927, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 927, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1326, in convert
    return t.to(
           ^^^^^
  File "/scratch/phys/sin/sethih1/venv/masque_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1326, in convert
    return t.to(
           ^^^^^
RuntimeError: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

RuntimeError: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

wandb: uploading history steps 0-1, summary, console lines 1-48
wandb: uploading summary, console lines 2-48
wandb:
wandb:
wandb: Run history:
wandb: final_dice ‚ñÅ‚ñÅ
wandb:      trial ‚ñà‚ñÅ
wandb:
wandb: Run summary:
wandb: final_dice 0
wandb:      trial 2
wandb:
wandb: üöÄ View run trial_3_bs128_lr1e-05_dice_loss at: https://wandb.ai/sethih10-epfl/Extended_TERS_data/runs/6l2yu577
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/sethih10-epfl/Extended_TERS_data
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251021_111252-6l2yu577/logs
[I 2025-10-21 11:12:57,407] Trial 3 finished with value: 0.0 and parameters: {'batch_size': 128, 'lr': 1.2917623332073263e-05, 'loss_fn': 'dice_loss', 'augmentation': True, 'filters_idx': 1, 'in_channels': 400, 'att_channels': 16}. Best is trial 3 with value: 0.0.
wandb:
wandb: üöÄ View run trial_2_bs16_lr2e-05_dice_loss at: https://wandb.ai/sethih10-epfl/Extended_TERS_data/runs/qt3o1rjd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/sethih10-epfl/Extended_TERS_data
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251021_111252-qt3o1rjd/logs
[I 2025-10-21 11:12:57,418] Trial 2 finished with value: 0.0 and parameters: {'batch_size': 16, 'lr': 2.266587938611815e-05, 'loss_fn': 'dice_loss', 'augmentation': True, 'filters_idx': 1, 'in_channels': 100, 'att_channels': 32}. Best is trial 3 with value: 0.0.
